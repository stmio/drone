[base]
package = ocean
env_name = puffer_drone_swarm
policy_name = Policy
rnn_name = Recurrent

[policy]
hidden_size = 128

[rnn]
input_size = 128
hidden_size = 128

[vec]
num_envs = 8

[env]
num_envs = 16
num_drones = 64
max_rings = 10

[train]
adam_beta1 = 0.9610890980775877
adam_beta2 = 0.9999260775286266
adam_eps = 7.782906079040132e-10
anneal_lr = true
batch_size = auto
bptt_horizon = 64
checkpoint_interval = 200
clip_coef = 0.05982655642208556
ent_coef = 0.002465076521024325
gae_lambda = 0.9641173414828333
gamma = 0.997472126425902
learning_rate = 0.010933756713881205
#learning_rate = 0.005
max_grad_norm = 1.6317688647793107
max_minibatch_size = 32768
minibatch_size = 32768
prio_alpha = 0.8968873016577552
prio_beta0 = 0.8672928227817938
total_timesteps = 500_000_000
update_epochs = 1
#use_rnn = false
vf_clip_coef = 0.5869845581530236
vf_coef = 2.1319065538539963
vtrace_c_clip = 2.714930379733876
vtrace_rho_clip = 3.8183814893708057

[sweep]
downsample = 0

[sweep.train.total_timesteps]
distribution = log_normal
min = 2e8
max = 4e8
mean = 2e8
scale = time
